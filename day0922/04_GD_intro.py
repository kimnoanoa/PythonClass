# - 선형회귀
# 독립변수와 종속변수 사이의 선형관계를 모델링하는 기법
# 알려진 데이터 값을 사용해서 알 수 없는 데이터의 값을 예측함
# 선형 방정식으로 모델링
# 실제값 y와 예측값y의 차이를 최소화하는 데 목적이 있음
# 학생이 공부한 시간에 따라 시험점수를 예측하거나 , 광고비 지출이 매출에 어떤 영향을 주는지 분석하고 싶을 때 선형회귀를 사용함
# ( 특성과 결과가 선형관계일때!)
# 장점 : 구현과 해석이 쉽고 계산 비용이 낮음. 결과가 직관적임
# 단점 : 이상치 민감, 비선형일 시 성능저하, 다중공선성 문제 발생 가능성 있음

# -릿지회귀
# 선형회귀에다 L2규제를 추가해서 과적합을 방지하는 기법
# 가중치 크기를 작게 만들어서 모델 복잡도를 감소시킴
# 장점 : 가중치를 0에 가깝게 작게 만들어 과적합 감소를 시킬 수 있고 안정적임
# 단점 : 변수 선택 기능 없음

# -라쏘회귀
# 선형회귀에 L1 규제를 추가함
# 그리고 일부 가중치를 0으로 만들어서 특성 선택이 가능함
# 희소 모델 생성이 가능하고, 변수 선택이 가능함
# 장점 : 일부 가중치를 정확히 0으로 만들어 특성 선택이 가능하며
# 모델 해석과 관리가 용이함
# 단점 : 변수들 간 강한 상관관계가 있으면 선택이 불안정해질 수 있음

# -로지스틱회귀
# 이진분류에서 확률을 예측할 수 있음 (예측은 0과 1 사이의 값)
# 0은 발생할 가능성이 낮은 이벤트, 1은 발생할 가능성이 높은 이벤트
# 스포츠 우승 또는 패배 확률 /  테스트 통과 또는 탈락 확률 같은 것을 나타냄
# (예/아니오) 또는 (참/ 거짓), (양성/음성)
# 장점 : 해석 용이, 구현과 학습이 빠르고 안정적임
# 단점 : 복잡한 비선형관계는 모델링하기 어려움, 클래스 미분리 시 성능이 제한됨


# -손실함수(비용함수)
# 모델 예측과 실제값 간의 차이를 수치로 나타내는 함수
# 손실 함수의 값을 최소화하는 파라미터를 찾음
# 장점 : 학습목표 명확
# 단점 : 설계가 부적절할 시 학습 실패 가능성이 있음

# -MSE
# 실제값과 예측값 차이의 제곱 평균
# 큰 오차에 대해서 더 큰 패널티를 부여함
# 장점 : 큰 오차에 더 큰 패널티 부여함 (민감도가 높음)
# 단점 : 이상치에 매우 민감함

# -최소제곱오차
# 선형회귀에서 파라미터를 추정하는 방법 중 하나
# MSE와 동일하고, 해석적 해 존재함(정규방정식)
# 선형회귀 파라미터를 추정할 때나 데이터에 대해 가장 적합한 직선을 찾고 싶을 때 사용함
# 장점 : 계산이 효율적임
# 단점 : 이상치에 취약, 비선형문제엔 사용x

# -경사하강법
# 손실 함수의 기울기를 따라서 파라미터를 업데이트하여 최소값을 찾는 
# 최적화 알고리즘
# 반복적으로 파라미터를 갱신함
# 해석적 해를 구하기 어려운 복잡한 모델 학습 시 이용함
# 장점 : 다양한 모델에 적용이 가능함, 대규모데이터에도 확장성 굿
# 단점 : 학습률 설정 어려움(너무크면 발산, 너무작으면 느림)

# -규제항
# 모델의 복잡도를 제한해서 과적합을 방지함
# 가중치 크기를 제한하여 모델 일반화 성능이 향상됨
# 장점 : 일반화 성능 향상, 불필요한 파라미터 축소
# 단점 : 규제 강도 조절이 중요함, 적절한 규제종류를 선택해야 함

# -시그모이드
# 실수 값을 0과 1 사이의 값으로 변환함
# 로지스틱 회귀의 출력 함수로 사용하거나, 확률 해석이 가능함
# 신경망의 활성화 함수로도 이용됨
# 장점 : 확률해석 가능
# 단점 :  큰 입력값을 넣으면 그래디언트 소실(기울기 값이 점점 작아져 0에 가까워지는 현상) 이 발생함 
# -> 깊은 신경망을 학습하기 어렵고, 매우 느려지거나 멈추게 됨

# -특성공학
# 원본 데이터만으로는 성능이 부족할 때 주로 사용하거나, 머신러닝 모델 성능을 높이기 위해 
# 원본 데이터에서 새로운 특성을 생성하고 변환하는 과정임. 
# 예로는 스케일링, 정규화, 다항 특성 생성, 범주형 변수 인코딩, 결측치 처리 등이 있음
# 장점 : 모델 성능 대폭 향상 가능, 데이터 이해도 증진
# 단점 : 시간과 노력이 많이 듬, 잘못된 특성이 있으면 성능저하를 유발함

# -BCE (바이너리 크로스 엔트로피)
# 이진분류에서 예측확률과 실제 라벨 간 차이를 측정하는 손실함수
# 확률 출력에 적합함
# 로지스틱 회귀나 신경망 이진분류에서 주로 사용됨
# 장점 : 확률기반 출력에 정합, 미분이 가능해서 최적화에 적합함
# 단점 : 확률값이 0이나 1에 가까울 시 수치적 불안정이 발생할 수 있음

